{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of Image Processing for use of image detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial you will be walked through how to develop an image processing program that will be used to detect if an image contains a firearm or not. In order to implement this program we will be exploring the TensorFlow package in Python. The implications of this program is to detect weapons on security cameras. However, for this tutorial, we will be limited to analyzing pictures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Image Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to teach a program how to recognize object we have to introduce deep learning to a program. Deep Leaning is a subset of Machine Learning that is used to primarily detect patterns in data. Deep learning is great at recognizing patterns because it utilizes multiple levels of nueral networks. Each layer (usually 3 or more) is tasked with extracting a certain peice or peices of information. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1600/1*590A1_2nItX49wqZKOlaFw.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://cdn-images-1.medium.com/max/1600/1*590A1_2nItX49wqZKOlaFw.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this is to teach a program to recognize certain aspects of images and classify the images into categories accordingly. To do this, you need to feed the algorithm pictures of the data that you want it to recognize so that the program can learn patterns in the desired images. Once an algorithm has analyzed enough images it will be able to be applied to random images and decide whether or not those images contain the desired pattern and sort them accordingly. \n",
    "\n",
    "There are multiple ways to do this but we are going to look at the two most popular ways for this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grayscale Image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grayscale image processing first involves converting an image into a black and white image. The reason for this is because we want to evalute how light or dark each pixel is and develop a pattern off of that. This is helpful when you are looking for patterns that are not based on color of the object but more on the shape or darkness of the image. Step two of Grayscale is assigning a numerical value to each pixel based on the darkness of the respected pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1600/1*-xaK2HVoN-zI4rNXKCtjew.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://cdn-images-1.medium.com/max/1600/1*-xaK2HVoN-zI4rNXKCtjew.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next step is place the values in an array and train the algorithm with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/2000/1*GX_7J9C2vq-Pr_GIKZLP0Q.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url = \"https://cdn-images-1.medium.com/max/2000/1*GX_7J9C2vq-Pr_GIKZLP0Q.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Convolutional Neural Networks (CNNs for short)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"Instead of feeding the entire image as an array of numbers, the image is broken up into a number of tiles, the machine then tries to predict what each tile is. Finally, the computer tries to predict whatâ€™s in the picture based on the prediction of all the tiles. This allows the computer to parallelize the operations and detect the object regardless of where it is located in the image.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Keras and TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Keras is the package that will be used for this example. Keras is a package that is built on top of the TensorFlow package. TensorFlow is a package developed by Google Brain team. The package was developed as a math package specifically targeted at machine learning and neaural networks.\n",
    "\n",
    "Keras was developed on top of TensorFlow with the intent of allowing fast experimentation while also being easy to use and adaptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to develop a CNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: is to import the proper package and install them to your system if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Based and modified on the keras example located here:\n",
    "https://github.com/venkateshtata/cnn_medium./commit/9d36a8a5c46d9974d2d4808192dfd27d582dce87\"\"\"\n",
    "\n",
    "# Convolutional Neural Network\n",
    "# Installing Theano\n",
    "# pip install --upgrade --no-deps git+git://github.com/Theano/Theano.git\n",
    "\n",
    "\n",
    "# Installing Tensorflow\n",
    "# pip install tensorflow\n",
    "\n",
    "# Installing Keras\n",
    "# pip install --upgrade keras\n",
    "\n",
    "\n",
    "# Part 1 - Building the CNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "import numpy\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import pickle\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to know what packages we are importing here since keras is able to do much of the work for us, let's explore what each of these are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is two ways to initialize a nueral network, one is Sequential memaning that there is a sequence of layers and the other being Graph. You would use a graph when your data is more alphanumeric. Since we are using images we want to use sequence. Sequence also allows for greater control over the network because it has multiple levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv2D is imported from layers because it will be used to do the Convolution needed for the network.This will be used to form each layer of the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MaxPooling will be used to assign a value to each pixel in the image. This is step 2 of building our network. There are other types of pooling such as Min Pooling, mean Pooling. We are using Max Pooling because max Pooling will grab the maxium pixel value of the region of the picture.\n",
    "\n",
    "Pooling is extradinary useful because it reduces a lot of the processing power needed in order to process images. It does this by seperating the images into quadrants and then taking a Max/Min/Mean value of the quadrant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The flatten package is used to convert all the 2 dimensional arrays resulting from the MaxPooling2D command and convert them into a one dimensional array to be inputed into the CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dense is used to create the full connection of the CNN. It specifies the shape of the data being inputed. (more on this later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Gather the appropriate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a function that would be used if you needed to process raw images from the internet or private sources. For our purposes, the database of images have been pre-process already but I thought I would include this just in case. The function randomizes certain aspects of the images such as flip, contrast, brightness, saturation, etc. This is done so that the CNN has a deeper understanding of what it's looking for. By randomizing these properties the CNN is better at detecting non test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_process_image(image):\n",
    "    # This function takes a single image as input,    \n",
    "\n",
    "        # Randomly crop the input image.\n",
    "        image = tf.random_crop(image, size=[img_size_cropped, img_size_cropped, num_channels])\n",
    "\n",
    "        # Randomly flip the image horizontally.\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        \n",
    "        # Randomly adjust hue, contrast and saturation.\n",
    "        image = tf.image.random_hue(image, max_delta=0.05)\n",
    "        image = tf.image.random_contrast(image, lower=0.3, upper=1.0)\n",
    "        image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "        image = tf.image.random_saturation(image, lower=0.0, upper=2.0)\n",
    "\n",
    "        # Some of these functions may overflow and result in pixel\n",
    "        # values beyond the [0, 1] range. It is unclear from the\n",
    "        # documentation of TensorFlow 0.10.0rc0 whether this is\n",
    "        # intended. A simple solution is to limit the range.\n",
    "\n",
    "        # Limit the image pixels between [0, 1] in case of overflow.\n",
    "        image = tf.minimum(image, 1.0)\n",
    "        image = tf.maximum(image, 0.0)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "# Load the data set\n",
    "X, Y, X_test, Y_test = pickle.load(open(\"full_dataset.pkl\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "\n",
    "This step initializes the object that will become the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Creating the CNN\n",
    "\n",
    "This is the most important step of the program. Because of Keras ease of use we can create the basis of the CNN in one line. Lets dissect this piece by piece\n",
    "\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Convert 2D array to a one-dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_database[]  \n",
    "for image_path in glob.glob(\"/home/adam/*.png\"):\n",
    "    Training_datab = misc.imread(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Apply algorithm to random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Convolution\n",
    "network = conv_2d(network, 32, 3, activation='relu')\n",
    "\n",
    "# Step 2: Max pooling\n",
    "network = max_pool_2d(network, 2)\n",
    "\n",
    "# Step 3: Convolution again\n",
    "network = conv_2d(network, 64, 3, activation='relu')\n",
    "\n",
    "# Step 4: Convolution yet again\n",
    "network = conv_2d(network, 64, 3, activation='relu')\n",
    "\n",
    "# Step 5: Max pooling again\n",
    "network = max_pool_2d(network, 2)\n",
    "\n",
    "# Step 6: Fully-connected 512 node neural network\n",
    "network = fully_connected(network, 512, activation='relu')\n",
    "\n",
    "# Step 7: Dropout - throw away some data randomly during training to prevent over-fitting\n",
    "network = dropout(network, 0.5)\n",
    "\n",
    "# Step 8: Fully-connected neural network with two outputs (0=isn't a bird, 1=is a bird) to make the final prediction\n",
    "network = fully_connected(network, 2, activation='softmax')\n",
    "\n",
    "# Tell tflearn how we want to train the network\n",
    "network = regression(network, optimizer='adam',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     learning_rate=0.001)\n",
    "\n",
    "# Wrap the network in a model object\n",
    "model = tflearn.DNN(network, tensorboard_verbose=0, checkpoint_path='bird-classifier.tfl.ckpt')\n",
    "\n",
    "# Train it! We'll do 100 training passes and monitor it as it goes.\n",
    "model.fit(X, Y, n_epoch=100, shuffle=True, validation_set=(X_test, Y_test),\n",
    "          show_metric=True, batch_size=96,\n",
    "          snapshot_epoch=True,\n",
    "          run_id='bird-classifier')\n",
    "\n",
    "# Save model when training is complete to a file\n",
    "model.save(\"bird-classifier.tfl\")\n",
    "print(\"Network trained and saved as bird-classifier.tfl!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@tifa2up/image-classification-using-deep-neural-networks-a-beginner-friendly-approach-using-tensorflow-94b0a090ccd4\n",
    "https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721\n",
    "https://github.com/tflearn/tflearn/tree/master/examples#tflearn-examples\n",
    "https://www.quora.com/What-is-max-pooling-in-convolutional-neural-networks\n",
    "https://www.tensorflow.org/get_started/\n",
    "https://github.com/venkateshtata/cnn_medium./tree/master\n",
    "https://keras.io/\n",
    "https://keras.io/layers/containers/\n",
    "https://keras.io/getting-started/sequential-model-guide/\n",
    "https://www.tensorflow.org/api_docs/python/tf/nn/conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
